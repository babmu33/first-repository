{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import copy\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kitti',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "TakeDataset = ds_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in TakeDataset:  \n",
    "    print('--Example--')\n",
    "    print(list(example.keys())) # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    image = example[\"image\"]\n",
    "    filename = example[\"image/file_name\"].numpy().decode('utf-8')\n",
    "    objects = example[\"objects\"]\n",
    "\n",
    "print('--objects--')\n",
    "print(objects)\n",
    "img = Image.fromarray(image.numpy())\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(input_image, object_bbox):\n",
    "    input_image = copy.deepcopy(input_image)\n",
    "    draw = ImageDraw.Draw(input_image)\n",
    "\n",
    "    # 바운딩 박스 좌표(x_min, x_max, y_min, y_max) 구하기\n",
    "    width, height = img.size\n",
    "    print(width, height)\n",
    "    print(object_bbox.shape)\n",
    "    x_min = object_bbox[:,1] * width\n",
    "    x_max = object_bbox[:,3] * width\n",
    "    y_min = height - object_bbox[:,0] * height\n",
    "    y_max = height - object_bbox[:,2] * height\n",
    "    \n",
    "    # 바운딩 박스 그리기\n",
    "    rects = np.stack([x_min, y_min, x_max, y_max], axis=1)\n",
    "    for _rect in rects:\n",
    "        draw.rectangle(_rect, outline=(255,0,0), width=2)\n",
    "    return input_image\n",
    "\n",
    "visualize_bbox(img, objects['bbox'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.getenv('HOME')+'/aiffel/object_detection/data'\n",
    "img_dir = os.getenv('HOME')+'/kitti_images'\n",
    "train_csv_path = data_dir + '/kitti_train.csv'\n",
    "\n",
    "# parse_dataset 함수를 구현해 주세요.\n",
    "def parse_dataset(dataset, img_dir=\"kitti_images\", total=0):\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "\n",
    "    type_class_map = {\n",
    "        0: \"car\",\n",
    "        1: \"car\",\n",
    "        2: \"car\",\n",
    "        3: \"person\",\n",
    "        4: \"person\",\n",
    "        5: \"person\",\n",
    "    }\n",
    "    df = pd.DataFrame(columns=[\"img_path\", \"x1\", \"y1\", \"x2\", \"y2\", \"class_name\"])\n",
    "    for item in tqdm(dataset, total=total):\n",
    "        filename = item['image/file_name'].numpy().decode('utf-8')\n",
    "        img_path = os.path.join(img_dir, filename)\n",
    "        \n",
    "        img = Image.fromarray(item['image'].numpy())\n",
    "        img.save(img_path)\n",
    "        object_bbox = item['objects']['bbox']\n",
    "        object_type = item['objects']['type'].numpy()\n",
    "        width, height = img.size\n",
    "        \n",
    "        x_min = object_bbox[:,1] * width\n",
    "        x_max = object_bbox[:,3] * width\n",
    "        y_min = height - object_bbox[:,2] * height\n",
    "        y_max = height - object_bbox[:,0] * height\n",
    "        \n",
    "        rects = np.stack([x_min, y_min, x_max, y_max], axis=1).astype(np.int)\n",
    "        for i, _rect in enumerate(rects):\n",
    "            _type = object_type[i]\n",
    "            if _type not in type_class_map.keys():\n",
    "                continue\n",
    "            df = df.append({\n",
    "                \"img_path\": img_path,\n",
    "                \"x1\": _rect[0],\n",
    "                \"y1\": _rect[1],\n",
    "                \"x2\": _rect[2],\n",
    "                \"y2\": _rect[3],\n",
    "                \"class_name\": type_class_map[_type]\n",
    "            }, ignore_index=True)\n",
    "            break\n",
    "    return df\n",
    "    \n",
    "df_train = parse_dataset(ds_train, img_dir, total=ds_info.splits['train'].num_examples)\n",
    "df_train.to_csv(train_csv_path, sep=',',index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = data_dir + '/kitti_test.csv'\n",
    "\n",
    "df_test = parse_dataset(ds_test, img_dir, total=ds_info.splits['test'].num_examples)\n",
    "df_test.to_csv(test_csv_path, sep=',',index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_txt_path = data_dir + '/classes.txt'\n",
    "\n",
    "def save_class_format(path=\"./classes.txt\"):\n",
    "    class_type_map = {\n",
    "        \"car\" : 0,\n",
    "        \"person\": 1\n",
    "    }\n",
    "    with open(path, mode='w', encoding='utf-8') as f:\n",
    "        for k, v in class_type_map.items():\n",
    "            f.write(f\"{k},{v}\\n\")\n",
    "\n",
    "save_class_format(class_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetinaNet 훈련이 시작됩니다!! 50epoch 훈련에 1시간 이상 소요될 수 있습니다. \n",
    "!python ~/aiffel/object_detection/keras-retinanet/keras_retinanet/bin/train.py --gpu 0 --multiprocessing --workers 4 --batch-size 2 --epochs 50 --steps 195 csv ~/aiffel/object_detection/data/kitti_train.csv ~/aiffel/object_detection/data/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.models import load_model\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "gpu = '0'\n",
    "setup_gpu(gpu)\n",
    "\n",
    "model_path = os.path.join('.', 'snapshots', 'resnet50_csv_50_infer.h5')\n",
    "model = load_model(model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_path = 'data/test_set/go_1.png'\n",
    "\n",
    "# inference_on_image 함수를 구현해 주세요.\n",
    "def inference_on_image(model, img_path=\"./test_set/go_1.png\", visualize=True):\n",
    "    image = read_image_bgr(img_path)\n",
    "\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    color_map = {\n",
    "        0: (0, 0, 255), # blue\n",
    "        1: (255, 0, 0) # red\n",
    "    }\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # display images\n",
    "    if  visualize:\n",
    "        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            print(box)\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            b = box.astype(int)\n",
    "            draw_box(draw, b, color=color_map[label])\n",
    "\n",
    "            caption = \"{:.3f}\".format(score)\n",
    "            draw_caption(draw, b, caption)\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(draw)\n",
    "        plt.show()            \n",
    "\n",
    "inference_on_image(model, img_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/test_set/stop_1.png'\n",
    "inference_on_image(model, img_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/test_set/stop_3.png'\n",
    "\n",
    "def self_drive_assist(img_path, size_limit=300):\n",
    "    image = read_image_bgr(img_path)\n",
    "\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    color_map = {\n",
    "        0: (0, 0, 255), # blue\n",
    "        1: (255, 0, 0) # red\n",
    "    }\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # 만약 사람이 1명 이상이면 멈춘다.\n",
    "        if label == 1:\n",
    "            return \"Stop\"\n",
    "        \n",
    "        elif label == 0:\n",
    "            width = box[2] - box[0]\n",
    "            height = box[3] - box[1]\n",
    "            # 사람이 아닌 경우 width와 height 둘 중 하나가 300 이상이면 'Stop'\n",
    "            if width > 300 or height > 300:\n",
    "                return \"Stop\"\n",
    "        # 둘다 아니라면 그냥 간다.    \n",
    "        if score < 0.5:\n",
    "            return \"Go\"\n",
    "\n",
    "print(self_drive_assist(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def test_system(func):\n",
    "    work_dir = 'data/'\n",
    "    score = 0\n",
    "    test_set=[\n",
    "        (\"test_set/stop_1.png\", \"Stop\"),\n",
    "        (\"test_set/stop_2.png\", \"Stop\"),\n",
    "        (\"test_set/stop_3.png\", \"Stop\"),\n",
    "        (\"test_set/stop_4.png\", \"Stop\"),\n",
    "        (\"test_set/stop_5.png\", \"Stop\"),\n",
    "        (\"test_set/go_1.png\", \"Go\"),\n",
    "        (\"test_set/go_2.png\", \"Go\"),\n",
    "        (\"test_set/go_3.png\", \"Go\"),\n",
    "        (\"test_set/go_4.png\", \"Go\"),\n",
    "        (\"test_set/go_5.png\", \"Go\"),\n",
    "    ]\n",
    "\n",
    "    for image_file, answer in test_set:\n",
    "        image_path = work_dir + '/' + image_file\n",
    "        pred = func(image_path)\n",
    "        if pred == answer:\n",
    "            score += 10\n",
    "    print(f\"{score}점입니다.\")\n",
    "\n",
    "test_system(self_drive_assist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-lemon",
   "metadata": {},
   "source": [
    "Report\n",
    "KITTI 데이터셋은 자율주행을 위한 데이터셋으로 2D object detection 뿐만 아니라 깊이까지 포함한 3d object detection 라벨을 제공하고 있다. 아직은 object Detection에 대한 지식을 배우느라 2D 라벨만 활용하지만, 기회가 되면 depth 정보를 활용한 3차원 Detection도 하고 싶다. 그리고 좀 더 많은 test 이미지로 다양한 테스트를 해보고 싶었지만, 이미지로 된 데이터를 구하기 힘들었다.\n",
    "\n",
    "함수를 평가하는 방법도 사람인지 아닌지, 또 자동차면 어느정도 사이즈가 되는 지에 따라 달라진다. 자율주행의 핵심은 원하는 위치에 스스로 가는 것이지만, 안전이 최우선이기 때문에 사람이나 가까운 자동차가 있으면 무조건 Stop을 해야된다. 더욱 다양한 상황을 실험해보고 싶지만 모델이 정상적으로 작동하는 모습을 보고 만족했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
